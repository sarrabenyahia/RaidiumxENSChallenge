{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment Anything Model as Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import watershed, felzenszwalb\n",
    "from skimage.filters import sobel\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import rank\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import disk\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train labels\n",
    "# Note the transpose!\n",
    "data_dir = Path(\"./../../data/\")\n",
    "labels_train = pd.read_csv(data_dir  / \"Y_train.csv\", index_col=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a function to load the data\n",
    "def load_dataset(dataset_dir):\n",
    "    dataset_list = []\n",
    "    # Note: It's very important to load the images in the correct numerical order!\n",
    "    for image_file in list(sorted(Path(dataset_dir).glob(\"*.png\"), key=lambda filename: int(filename.name.rstrip(\".png\")))):\n",
    "        dataset_list.append(cv2.imread(str(image_file), cv2.IMREAD_GRAYSCALE))\n",
    "    return np.stack(dataset_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test sets\n",
    "# If you've put the shortcut directly in your drive, this should work out of the box\n",
    "# Else, edit the path\n",
    "data_dir = Path(\"./../../data/\")\n",
    "data_train = load_dataset(data_dir / \"X_train\")\n",
    "data_test = load_dataset(data_dir / \"X_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1000, 512, 512)\n",
      "Y_train shape: (1000, 262144)\n"
     ]
    }
   ],
   "source": [
    "# The train data is a numpy array of 1000 images of 512*512\n",
    "print(f\"X_train shape: {data_train.shape}\")\n",
    "# The train label is a dataframe of 1000 rows with 262144 (=512x512) columns\n",
    "print(f\"Y_train shape: {labels_train.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On travaille ici sur les X_train qui sont labelisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Spécifiez le chemin d'accès au dossier contenant les images\n",
    "path_to_X_train = './../../data/X_train/'\n",
    "\n",
    "# Créez un nouveau dossier pour les 200 premières images\n",
    "path_to_X_train_ground_truth = './../../data/X_train_ground_truth'\n",
    "os.mkdir(path_to_X_train_ground_truth)\n",
    "\n",
    "# Copiez les 200 premières images dans le nouveau dossier\n",
    "for i in range(201):\n",
    "    image_path = os.path.join(path_to_X_train, str(i) + '.png')\n",
    "    ground_truth_path = os.path.join(path_to_X_train_ground_truth, str(i) + '.png')\n",
    "    shutil.copyfile(image_path, ground_truth_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "sam = sam_model_registry[\"vit_l\"](checkpoint=\"/Users/sarrabenyahia/Documents/GitHub/MedSAM/checkpoints_sam/sam_vit_l_0b3195.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Replace this with the path to your X_test directory : Ici on prends les X_train car on n'entraine pas dessus et c'est les seules fichiers où on a un ground truth pour  calculer les métriques\n",
    "x_test_dir = './../../data/X_train_ground_truth/'\n",
    "\n",
    "# Create the predictions directory if it does not exist\n",
    "predictions_dir = './../../data/predictions/inference_sam/'\n",
    "os.makedirs(predictions_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the SamAutomaticMaskGenerator object\n",
    "sam = sam_model_registry[\"vit_l\"](checkpoint=\"/Users/sarrabenyahia/Documents/GitHub/MedSAM/checkpoints_sam/sam_vit_l_0b3195.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Loop over each image in the directory\n",
    "for filename in os.listdir(x_test_dir):\n",
    "    # Read the image and convert it to RGB\n",
    "    image = cv2.imread(os.path.join(x_test_dir, filename))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Generate the mask using the SamAutomaticMaskGenerator object\n",
    "    mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "    masks = mask_generator.generate(image)\n",
    "\n",
    "    # Write data to CSV file\n",
    "    with open(f'{predictions_dir}{filename}.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['segmentation', 'area', 'bbox', 'predicted_iou', 'point_coords', 'stability_score', 'crop_box'])\n",
    "        for mask in masks:\n",
    "            writer.writerow([mask['segmentation'], mask['area'], mask['bbox'], mask['predicted_iou'], mask['point_coords'], mask['stability_score'], mask['crop_box']]) \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ajouter viz entre inférence et ground truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Plot the image and mask\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.imshow(image)\n",
    "    show_anns(masks)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ajouter métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
