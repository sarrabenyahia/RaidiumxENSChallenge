{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import UpSampling2D, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a function to load the data\n",
    "def load_dataset(dataset_dir):\n",
    "    dataset_list = []\n",
    "    # Note: It's very important to load the images in the correct numerical order!\n",
    "    for image_file in list(sorted(Path(dataset_dir).glob(\"*.png\"), key=lambda filename: int(filename.name.rstrip(\".png\")))):\n",
    "        dataset_list.append(cv2.imread(str(image_file), cv2.IMREAD_GRAYSCALE))\n",
    "    return np.stack(dataset_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test sets\n",
    "# If you've put the shortcut directly in your drive, this should work out of the box\n",
    "# Else, edit the path\n",
    "data_dir = Path(\"./../data/\")\n",
    "data_train = load_dataset(data_dir / \"X_train\")\n",
    "data_test = load_dataset(data_dir / \"X_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1000, 512, 512)\n",
      "Y_train shape: (1000, 262144)\n"
     ]
    }
   ],
   "source": [
    "# The train data is a numpy array of 1000 images of 512*512\n",
    "print(f\"X_train shape: {data_train.shape}\")\n",
    "# The train label is a dataframe of 1000 rows with 262144 (=512x512) columns\n",
    "print(f\"Y_train shape: {labels_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
